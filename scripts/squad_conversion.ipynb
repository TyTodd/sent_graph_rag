{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQUAD Dataset Conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define dataset reader class for SQuAD dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_json_schema(data, indent=0):\n",
    "    \"\"\"Recursively print the schema of a JSON object.\"\"\"\n",
    "    if isinstance(data, dict):\n",
    "        print(\" \" * indent + \"{\")\n",
    "        for key, value in data.items():\n",
    "            print(\" \" * (indent + 2) + f'\"{key}\": {type(value).__name__}', end=\"\")\n",
    "            if isinstance(value, (dict, list)):\n",
    "                print(\" ->\")\n",
    "                print_json_schema(value, indent + 4)\n",
    "            else:\n",
    "                print(\",\")\n",
    "        print(\" \" * indent + \"}\")\n",
    "    elif isinstance(data, list):\n",
    "        print(\" \" * indent + \"[\")\n",
    "        if data:\n",
    "            print_json_schema(data[0], indent + 2)\n",
    "        else:\n",
    "            print(\" \" * (indent + 2) + \"Empty list\")\n",
    "        print(\" \" * indent + \"]\")\n",
    "    else:\n",
    "        print(\" \" * indent + f\"{type(data).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Datatset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tytodd/miniconda3/envs/sent_graph_rag/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/stanfordu/stanford-question-answering-dataset?dataset_version_number=2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8.73M/8.73M [00:01<00:00, 8.61MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /home/tytodd/.cache/kagglehub/datasets/stanfordu/stanford-question-answering-dataset/versions/2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"stanfordu/stanford-question-answering-dataset\", path=\"../data/squad/base\")\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%mv $path ../data/squad/base\n",
    "%mv ../data/squad/base/2/dev-v1.1.json ../data/squad/base/dev-v1.1.json\n",
    "%mv ../data/squad/base/2/train-v1.1.json ../data/squad/base/train-v1.1.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to SentenceGraphDataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create DatasetReader for SQUAD dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tytodd/miniconda3/envs/sent_graph_rag/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sent_graph_rag.Datasets import SentenceGraphDataset, DatasetReader\n",
    "import json\n",
    "\n",
    "class SQUADReader(DatasetReader):\n",
    "    \"\"\"\n",
    "    Reader for the SQuAD dataset.\n",
    "    \"\"\"\n",
    "    def __init__(self, file_path: str):\n",
    "        super().__init__(file_path)\n",
    "        with open(file_path, 'r') as f:\n",
    "            self.squad_data = json.load(f)\n",
    "        self.data_length = sum([sum([1 for i in topic['paragraphs']]) for topic in self.squad_data['data']])\n",
    "        \n",
    "    def read(self):\n",
    "        for topic in self.squad_data[\"data\"]:\n",
    "            for paragraph in topic[\"paragraphs\"]:\n",
    "                qas = []\n",
    "                for qa in paragraph[\"qas\"]:\n",
    "                    answers = [a[\"text\"] for a in qa[\"answers\"]]\n",
    "                    qas.append({\"question\": qa[\"question\"], \"answers\": answers})\n",
    "                yield {\"context\": paragraph[\"context\"], \"qas\": qas}\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return self.data_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/06/2025 03:10:38 - INFO - \t missing_keys: []\n",
      "04/06/2025 03:10:38 - INFO - \t unexpected_keys: []\n",
      "04/06/2025 03:10:38 - INFO - \t mismatched_keys: []\n",
      "04/06/2025 03:10:38 - INFO - \t error_msgs: []\n",
      "04/06/2025 03:10:38 - INFO - \t Model Parameters: 90.5M, Transformer: 82.1M, Coref head: 8.4M\n"
     ]
    }
   ],
   "source": [
    "from datasets.utils.logging import disable_progress_bar\n",
    "import spacy\n",
    "from spacy.pipeline import EntityLinker\n",
    "from fastcoref import spacy_component\n",
    "import logging\n",
    "\n",
    "disable_progress_bar()\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.add_pipe(\"fastcoref\",  config={'device': 'cuda:0', \"enable_progress_bar\": False})\n",
    "logging.getLogger(\"fastcoref\").setLevel(logging.WARNING)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Language.pipe at 0x738184ebdfe0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = [\"Hello, how are you?\", \"I am fine, thank you.\"]\n",
    "nlp.pipe(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting dataset: 100%|██████████| 18896/18896 [05:31<00:00, 56.93it/s] \n"
     ]
    }
   ],
   "source": [
    "from sent_graph_rag.Datasets import SentenceGraphDataset\n",
    "dataset_reader = SQUADReader(\"../data/squad/base/train-v1.1.json\")\n",
    "sentence_graph_dataset = SentenceGraphDataset.from_dataset(dataset_reader, \"../data/squad/graph/train.avro\", nlp=nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SentenceGraphDataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# dataset_reader = SQUADReader(\"../data/squad/base/train-v1.1.json\")\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# sentence_graph_dataset = SentenceGraphDataset.from_dataset(dataset_reader, \"../data/squad/graph/train.avro\", verbose = False)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m sentence_graph_dataset = \u001b[43mSentenceGraphDataset\u001b[49m(nlp, verbose = \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m      4\u001b[39m sentence_graph_dataset.embed_dataset(\u001b[33m\"\u001b[39m\u001b[33m../data/squad/graph/train.avro\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m../data/squad/graph/train_embed.avro\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'SentenceGraphDataset' is not defined"
     ]
    }
   ],
   "source": [
    "from sent_graph_rag.Datasets import SentenceGraphDataset\n",
    "# dataset_reader = SQUADReader(\"../data/squad/base/train-v1.1.json\")\n",
    "# sentence_graph_dataset = SentenceGraphDataset.from_dataset(dataset_reader, \"../data/squad/graph/train.avro\", verbose = False)\n",
    "sentence_graph_dataset = SentenceGraphDataset(nlp, verbose = False)\n",
    "sentence_graph_dataset.embed_dataset(\"../data/squad/graph/train.avro\", \"../data/squad/graph/train_embed.avro\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sent_graph_rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
